{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 â€” BraTS 2021 Data Quality Control\n",
    "\n",
    "Comprehensive QC: dataset overview, spacing/shape checks, intensity distributions, label statistics, sample visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_ROOT = Path('/workspace/DataChallenge/data/BraTS2021_Training_Data')\n",
    "OUT_DIR = Path('/workspace/brats-biohub/outputs/qc')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODALITIES = ['flair', 't1', 't1ce', 't2']\n",
    "\n",
    "subjects = sorted([d.name for d in DATA_ROOT.iterdir() if d.is_dir() and d.name.startswith('BraTS2021_')])\n",
    "print(f'Total subjects: {len(subjects)}')\n",
    "print(f'First 5: {subjects[:5]}')\n",
    "print(f'Last  5: {subjects[-5:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. File Completeness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check every subject has all expected files\n",
    "expected_suffixes = MODALITIES + ['seg']\n",
    "missing = []\n",
    "\n",
    "for sid in tqdm(subjects, desc='Checking files'):\n",
    "    for mod in expected_suffixes:\n",
    "        fpath = DATA_ROOT / sid / f'{sid}_{mod}.nii.gz'\n",
    "        if not fpath.exists():\n",
    "            missing.append((sid, mod))\n",
    "\n",
    "if missing:\n",
    "    print(f'WARNING: {len(missing)} missing files:')\n",
    "    for sid, mod in missing[:10]:\n",
    "        print(f'  {sid} / {mod}')\n",
    "else:\n",
    "    print(f'All {len(subjects)} subjects have complete files (4 modalities + seg).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shape & Spacing Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect metadata from all subjects (sample flair for shape/spacing)\n",
    "records = []\n",
    "for sid in tqdm(subjects, desc='Reading headers'):\n",
    "    nii = nib.load(str(DATA_ROOT / sid / f'{sid}_flair.nii.gz'))\n",
    "    shape = nii.shape\n",
    "    spacing = tuple(np.round(nii.header.get_zooms()[:3], 4))\n",
    "    records.append({\n",
    "        'subject': sid,\n",
    "        'x': shape[0], 'y': shape[1], 'z': shape[2],\n",
    "        'sx': spacing[0], 'sy': spacing[1], 'sz': spacing[2]\n",
    "    })\n",
    "\n",
    "df_meta = pd.DataFrame(records)\n",
    "print('=== Shape distribution ===')\n",
    "print(df_meta[['x', 'y', 'z']].describe().round(2))\n",
    "print(f'\\nUnique shapes: {df_meta[[\"x\",\"y\",\"z\"]].drop_duplicates().shape[0]}')\n",
    "print(df_meta[['x','y','z']].drop_duplicates())\n",
    "\n",
    "print('\\n=== Spacing distribution ===')\n",
    "print(df_meta[['sx', 'sy', 'sz']].describe().round(4))\n",
    "print(f'\\nUnique spacings: {df_meta[[\"sx\",\"sy\",\"sz\"]].drop_duplicates().shape[0]}')\n",
    "print(df_meta[['sx','sy','sz']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot shape and spacing distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, dim in enumerate(['x', 'y', 'z']):\n",
    "    axes[i].hist(df_meta[dim], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'Dimension {dim.upper()} distribution')\n",
    "    axes[i].set_xlabel('Voxels')\n",
    "    axes[i].set_ylabel('Count')\n",
    "plt.suptitle('Volume Shape Distribution', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUT_DIR / 'shape_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intensity Distributions (sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 50 subjects for intensity stats\n",
    "np.random.seed(42)\n",
    "sample_ids = np.random.choice(subjects, size=min(50, len(subjects)), replace=False)\n",
    "\n",
    "intensity_stats = defaultdict(list)\n",
    "\n",
    "for sid in tqdm(sample_ids, desc='Intensity stats'):\n",
    "    for mod in MODALITIES:\n",
    "        data = nib.load(str(DATA_ROOT / sid / f'{sid}_{mod}.nii.gz')).get_fdata()\n",
    "        brain = data[data > 0]  # non-zero voxels only\n",
    "        if len(brain) > 0:\n",
    "            intensity_stats[mod].append({\n",
    "                'subject': sid,\n",
    "                'mean': brain.mean(),\n",
    "                'std': brain.std(),\n",
    "                'min': brain.min(),\n",
    "                'max': brain.max(),\n",
    "                'p01': np.percentile(brain, 1),\n",
    "                'p99': np.percentile(brain, 99)\n",
    "            })\n",
    "\n",
    "for mod in MODALITIES:\n",
    "    df_int = pd.DataFrame(intensity_stats[mod])\n",
    "    print(f'\\n=== {mod.upper()} intensity (non-zero, n={len(df_int)}) ===')\n",
    "    print(df_int[['mean', 'std', 'min', 'max', 'p01', 'p99']].describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intensity distributions for 5 random subjects\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "plot_ids = sample_ids[:5]\n",
    "\n",
    "for ax, mod in zip(axes.flat, MODALITIES):\n",
    "    for sid in plot_ids:\n",
    "        data = nib.load(str(DATA_ROOT / sid / f'{sid}_{mod}.nii.gz')).get_fdata()\n",
    "        brain = data[data > 0]\n",
    "        ax.hist(brain, bins=100, alpha=0.4, density=True, label=sid[-5:])\n",
    "    ax.set_title(f'{mod.upper()} Intensity Distribution')\n",
    "    ax.set_xlabel('Intensity')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.set_xlim(0, np.percentile(brain, 99.5) * 1.2)\n",
    "\n",
    "plt.suptitle('Per-modality Intensity Distributions (5 subjects)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUT_DIR / 'intensity_distributions.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Label / Segmentation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect label stats for all subjects\n",
    "label_records = []\n",
    "LABEL_NAMES = {0: 'Background', 1: 'NCR/NET', 2: 'ED', 4: 'ET'}\n",
    "\n",
    "for sid in tqdm(subjects, desc='Label stats'):\n",
    "    seg = nib.load(str(DATA_ROOT / sid / f'{sid}_seg.nii.gz')).get_fdata().astype(int)\n",
    "    unique_labels = set(np.unique(seg))\n",
    "    total_voxels = seg.size\n",
    "    rec = {'subject': sid, 'unique_labels': str(sorted(unique_labels))}\n",
    "    for lbl, name in LABEL_NAMES.items():\n",
    "        count = int(np.sum(seg == lbl))\n",
    "        rec[f'{name}_count'] = count\n",
    "        rec[f'{name}_pct'] = round(100.0 * count / total_voxels, 4)\n",
    "    # Whole tumor = 1 + 2 + 4\n",
    "    rec['WT_count'] = rec['NCR/NET_count'] + rec['ED_count'] + rec['ET_count']\n",
    "    rec['WT_pct'] = round(rec['NCR/NET_pct'] + rec['ED_pct'] + rec['ET_pct'], 4)\n",
    "    label_records.append(rec)\n",
    "\n",
    "df_labels = pd.DataFrame(label_records)\n",
    "print('=== Label volume statistics (% of total volume) ===')\n",
    "pct_cols = [c for c in df_labels.columns if c.endswith('_pct')]\n",
    "print(df_labels[pct_cols].describe().round(4))\n",
    "\n",
    "print(f'\\n=== Unique label sets ===')\n",
    "print(df_labels['unique_labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tumor volume distributions\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "tumor_cols = ['NCR/NET_pct', 'ED_pct', 'ET_pct', 'WT_pct']\n",
    "colors = ['#e74c3c', '#2ecc71', '#3498db', '#9b59b6']\n",
    "\n",
    "for ax, col, color in zip(axes, tumor_cols, colors):\n",
    "    ax.hist(df_labels[col], bins=40, edgecolor='black', alpha=0.7, color=color)\n",
    "    ax.set_title(col.replace('_pct', '').replace('/', '-'))\n",
    "    ax.set_xlabel('% of total volume')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.axvline(df_labels[col].median(), color='red', linestyle='--', label=f'median={df_labels[col].median():.3f}')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Tumor Sub-region Volume Distribution (% of total)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUT_DIR / 'label_distributions.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of tumor volumes\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "count_cols = ['NCR/NET_count', 'ED_count', 'ET_count', 'WT_count']\n",
    "plot_data = df_labels[count_cols].copy()\n",
    "plot_data.columns = ['NCR/NET', 'ED', 'ET', 'Whole Tumor']\n",
    "# Convert to mL (1mm^3 voxels -> 1mm^3 = 0.001 mL)\n",
    "plot_data_ml = plot_data * 0.001  # assuming 1mm isotropic\n",
    "plot_data_ml.boxplot(ax=ax)\n",
    "ax.set_ylabel('Volume (mL)')\n",
    "ax.set_title('Tumor Sub-region Volume Distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUT_DIR / 'tumor_volume_boxplot.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Visualization (6 random subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 6 random subjects: all 4 modalities + seg overlay\n",
    "np.random.seed(123)\n",
    "vis_ids = np.random.choice(subjects, size=6, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(6, 5, figsize=(20, 24))\n",
    "col_titles = ['FLAIR', 'T1', 'T1ce', 'T2', 'Seg Overlay']\n",
    "\n",
    "# Colormap for segmentation\n",
    "from matplotlib.colors import ListedColormap\n",
    "seg_cmap = ListedColormap(['none', '#e74c3c', '#2ecc71', 'none', '#3498db'])\n",
    "\n",
    "for i, sid in enumerate(vis_ids):\n",
    "    volumes = {}\n",
    "    for mod in MODALITIES:\n",
    "        volumes[mod] = nib.load(str(DATA_ROOT / sid / f'{sid}_{mod}.nii.gz')).get_fdata()\n",
    "    seg = nib.load(str(DATA_ROOT / sid / f'{sid}_seg.nii.gz')).get_fdata().astype(int)\n",
    "    \n",
    "    # Find slice with most tumor\n",
    "    tumor_per_slice = np.sum(seg > 0, axis=(0, 1))\n",
    "    best_slice = np.argmax(tumor_per_slice)\n",
    "    \n",
    "    for j, mod in enumerate(MODALITIES):\n",
    "        sl = volumes[mod][:, :, best_slice]\n",
    "        vmax = np.percentile(sl[sl > 0], 99) if sl.max() > 0 else 1\n",
    "        axes[i, j].imshow(sl.T, cmap='gray', origin='lower', vmin=0, vmax=vmax)\n",
    "        axes[i, j].axis('off')\n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(col_titles[j], fontsize=13)\n",
    "    \n",
    "    # Seg overlay on FLAIR\n",
    "    flair_sl = volumes['flair'][:, :, best_slice]\n",
    "    seg_sl = seg[:, :, best_slice]\n",
    "    vmax = np.percentile(flair_sl[flair_sl > 0], 99) if flair_sl.max() > 0 else 1\n",
    "    axes[i, 4].imshow(flair_sl.T, cmap='gray', origin='lower', vmin=0, vmax=vmax)\n",
    "    masked_seg = np.ma.masked_where(seg_sl == 0, seg_sl)\n",
    "    axes[i, 4].imshow(masked_seg.T, cmap=seg_cmap, origin='lower', alpha=0.6, vmin=0, vmax=4)\n",
    "    axes[i, 4].axis('off')\n",
    "    if i == 0:\n",
    "        axes[i, 4].set_title(col_titles[4], fontsize=13)\n",
    "    \n",
    "    axes[i, 0].set_ylabel(sid[-5:], fontsize=11, rotation=0, labelpad=50)\n",
    "\n",
    "plt.suptitle('BraTS 2021 Sample Visualization (best tumor slice)', fontsize=16, y=1.005)\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(OUT_DIR / 'sample_visualization.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Figure saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. QC Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to CSV\n",
    "df_meta.to_csv(str(OUT_DIR / 'metadata.csv'), index=False)\n",
    "df_labels.to_csv(str(OUT_DIR / 'label_stats.csv'), index=False)\n",
    "\n",
    "print('=== QC Summary ===')\n",
    "print(f'Total subjects:     {len(subjects)}')\n",
    "print(f'Missing files:      {len(missing)}')\n",
    "print(f'Unique shapes:      {df_meta[[\"x\",\"y\",\"z\"]].drop_duplicates().shape[0]}')\n",
    "print(f'Unique spacings:    {df_meta[[\"sx\",\"sy\",\"sz\"]].drop_duplicates().shape[0]}')\n",
    "print(f'Mean WT volume %:   {df_labels[\"WT_pct\"].mean():.4f}')\n",
    "print(f'\\nSaved CSVs and figures to: {OUT_DIR}')\n",
    "print('\\nFiles generated:')\n",
    "for f in sorted(OUT_DIR.iterdir()):\n",
    "    print(f'  {f.name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
